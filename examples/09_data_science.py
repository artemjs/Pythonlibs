#!/usr/bin/env python3
"""
üìä Data Science —Å friendly_exceptions
Data Science with friendly_exceptions

–≠—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç –≤ data science
This example shows how the library helps in data science
"""

import friendly_exceptions
import json

print("üìä Data Science —Å friendly_exceptions")
print("üìä Data Science with friendly_exceptions")
print("=" * 50)

# –°–∏–º—É–ª—è—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
class DataProcessor:
    def __init__(self):
        self.datasets = {
            "sales": {"rows": 1000, "columns": ["date", "product", "amount", "region"]},
            "users": {"rows": 500, "columns": ["id", "name", "email", "age", "city"]},
            "products": {"rows": 200, "columns": ["id", "name", "price", "category"]}
        }
    
    def load_dataset(self, dataset_name):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        try:
            dataset = self.datasets[dataset_name]
            print(f"   –î–∞—Ç–∞—Å–µ—Ç '{dataset_name}' –∑–∞–≥—Ä—É–∂–µ–Ω:")
            print(f"   Rows: {dataset['rows']}")
            print(f"   Columns: {dataset['columns']}")
            return dataset
        except KeyError:
            pass  # friendly_exceptions –ø–æ–∫–∞–∂–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
    
    def analyze_data(self, data, analysis_type):
        """–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if analysis_type == "summary":
                return self._summary_stats(data)
            elif analysis_type == "correlation":
                return self._correlation_analysis(data)
            elif analysis_type == "trend":
                return self._trend_analysis(data)
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞: {analysis_type}")
        except (KeyError, ValueError, AttributeError):
            pass  # friendly_exceptions –æ–±—ä—è—Å–Ω–∏—Ç –ø—Ä–æ–±–ª–µ–º—É
    
    def _summary_stats(self, data):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–Ω—ã–º"""
        try:
            rows = data["rows"]
            columns = data["columns"]
            return {
                "total_rows": rows,
                "total_columns": len(columns),
                "column_names": columns
            }
        except (KeyError, TypeError):
            pass
    
    def _correlation_analysis(self, data):
        """–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        try:
            # –°–∏–º—É–ª–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            numeric_columns = [col for col in data["columns"] if col in ["amount", "price", "age"]]
            return f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É {numeric_columns}"
        except (KeyError, AttributeError):
            pass
    
    def _trend_analysis(self, data):
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤"""
        try:
            if "date" in data["columns"]:
                return "–¢—Ä–µ–Ω–¥ –ø–æ –¥–∞—Ç–µ –Ω–∞–π–¥–µ–Ω"
            else:
                raise ValueError("–ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤")
        except (KeyError, ValueError):
            pass

# –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–∞–Ω–Ω—ã—Ö
processor = DataProcessor()

print("\n1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:")
print("1Ô∏è‚É£ Loading datasets:")

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
dataset = processor.load_dataset("sales")

# –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
print("\n   –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç...")
dataset = processor.load_dataset("inventory")  # –ù–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

print("\n2Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö:")
print("2Ô∏è‚É£ Data analysis:")

# –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç
if dataset:
    print("   –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    result = processor.analyze_data(dataset, "summary")
    if result:
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    
    print("\n   –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:")
    result = processor.analyze_data(dataset, "correlation")
    if result:
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
    
    print("\n   –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤:")
    result = processor.analyze_data(dataset, "trend")
    if result:
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")

print("\n3Ô∏è‚É£ –†–∞–±–æ—Ç–∞ —Å JSON –¥–∞–Ω–Ω—ã–º–∏:")
print("3Ô∏è‚É£ Working with JSON data:")

def process_json_data(json_string):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ JSON –¥–∞–Ω–Ω—ã—Ö"""
    try:
        data = json.loads(json_string)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        records = data["records"]
        metadata = data["metadata"]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å
        for record in records:
            id = record["id"]
            value = record["value"]
            timestamp = record["timestamp"]
            
            print(f"   Record {id}: {value} at {timestamp}")
        
        return len(records)
        
    except (json.JSONDecodeError, KeyError, TypeError):
        pass  # friendly_exceptions –æ–±—ä—è—Å–Ω–∏—Ç –ø—Ä–æ–±–ª–µ–º—É

# –í–∞–ª–∏–¥–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ
valid_json = '''
{
    "metadata": {"source": "sensor", "version": "1.0"},
    "records": [
        {"id": 1, "value": 25.5, "timestamp": "2024-01-01T10:00:00"},
        {"id": 2, "value": 26.1, "timestamp": "2024-01-01T10:01:00"}
    ]
}
'''

print("   –í–∞–ª–∏–¥–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ:")
count = process_json_data(valid_json)
if count:
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {count}")

# –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ
invalid_json = '''
{
    "metadata": {"source": "sensor", "version": "1.0"},
    "records": [
        {"id": 1, "value": 25.5, "timestamp": "2024-01-01T10:00:00"},
        {"id": 2, "value": 26.1}
    ]
}
'''

print("\n   –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç timestamp):")
count = process_json_data(invalid_json)

print("\n4Ô∏è‚É£ –†–∞–±–æ—Ç–∞ —Å –º–∞—Å—Å–∏–≤–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö:")
print("4Ô∏è‚É£ Working with data arrays:")

def process_data_array(data_array, operation):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—Å–∏–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        if operation == "sum":
            return sum(data_array)
        elif operation == "average":
            return sum(data_array) / len(data_array)
        elif operation == "max":
            return max(data_array)
        elif operation == "min":
            return min(data_array)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è: {operation}")
    except (TypeError, ValueError, ZeroDivisionError):
        pass  # friendly_exceptions –æ–±—ä—è—Å–Ω–∏—Ç –ø—Ä–æ–±–ª–µ–º—É

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
data = [1, 2, 3, 4, 5]
print(f"   –î–∞–Ω–Ω—ã–µ: {data}")

result = process_data_array(data, "sum")
if result:
    print(f"   –°—É–º–º–∞: {result}")

result = process_data_array(data, "average")
if result:
    print(f"   –°—Ä–µ–¥–Ω–µ–µ: {result}")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
print("\n   –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏:")
result = process_data_array("not_a_list", "sum")  # –ù–µ —Å–ø–∏—Å–æ–∫
result = process_data_array([], "average")  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫

print("\n‚ú® Data Science —Å—Ç–∞–ª –ø—Ä–æ—â–µ —Å friendly_exceptions!")
print("‚ú® Data Science is easier with friendly_exceptions!")
print("\nüí° –°–æ–≤–µ—Ç: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö!")
print("üí° Tip: Use the library for debugging data processing!")
